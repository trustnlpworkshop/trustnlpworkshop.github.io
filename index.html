<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>TrustNLP</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/scrolling-nav.css" rel="stylesheet">

<style>
   table {border-collapse:collapse; table-layout:fixed; width:500px;}
   table td {border:solid 1px #fab; width:100px; word-wrap:break-word;}
   </style>

</head>

<body id="page-top">

<!-- Navigation -->
<nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
  <div class="container">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">TrustNLP @ NAACL 2025</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarResponsive">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#about">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#call-for-papers">Call for Papers</a>
        </li>          
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#speakers">Speakers</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#schedule">Schedule</a> 
        </li>          
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#papers">Papers</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#people">People</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#contact">Contact</a>
        </li>
      </ul>
    </div>
  </div>
</nav>

  <header class=" text-white" style="background-image: url('index.jpg')">
    <div class="container text-center">
      <h1>TrustNLP: Fifth Workshop on Trustworthy Natural Language Processing</h1>
      <p class="desc">Colocated with the <a style="color:white" href="https://2025.naacl.org/"> 2025 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2025)</a> </p>
      <p class="lead"></p>
    </div>
  </header>

  <section id="about" class="bg-light">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <h2>About </h2>
          <p class="lead">Recent advances in Natural Language Processing, and the emergence of pretrained Large Language Models (LLM) specifically, have led to significant breakthroughs in language understanding, generation, and interaction, leading to increasing usage of the models in real-life tasks. However, these advancements come with risks, including potential breaches of privacy, the propagation of bias, copyright violation, and vulnerabilities to adversarial manipulation. The demand for trustworthy NLP solutions is pressing as the public, policymakers, and organizations seek assurances that NLP systems protect data confidentiality, operate fairly, and adhere to ethical principles.
          <p class="lead">This year, we are excited to host our TrustNLP workshop at NAACL 2025, aimed at fostering discussions on these pressing challenges and driving the development of solutions that prioritize trustworthiness in NLP technologies. The workshop aspires to bring together researchers from various fields to engage in meaningful dialogue on key topics such as fairness and bias mitigation, transparency and explainability, privacy-preserving NLP methods, and the ethical deployment of AI systems. By providing a platform for sharing innovative research and practical insights, this workshop seeks to bridge the gaps between these interconnected objectives and establish a foundation for a more comprehensive and holistic approach to trustworthy NLP.
	</div>
      </div>
    </div>
  </section>



	
<section id="call-for-papers" class="bg-light">
  <div class="container">
    <div class="row">
      <!-- <div class="col-lg-8 mx-auto" tyle="margin-top: -150px;"> -->
        <div class="col-lg-8 mx-auto">

        <h2>Call for Papers</h2>
        <h4>Topics</h4>
        <p>We invite papers which focus on different aspects of <em>safe</em> and <em>trustworthy</em> language modeling. Topics of interest include (but are not limited to): 
        <ul style="padding-left: 20px;">
          <li>Secure, Faithful & Trustworthy Generation with LLMs</li>
	  <li>Data Privacy Preservation and Data Leakage Issues in LLMs</li>
	  <li>Red-teaming, backdoor or adversarial attacks and defenses for LLM safety</li>
          <li>Fairness, LLM alignment, Human Preference Elicitation, Participatory NLP</li>
          <li>Toxic Language Detection and Mitigation</li>
          <li>Explainability and Interpretability of LLM generation</li>
          <li>Robustness of LLMs</li>
          <li>Mitigating LLM Hallucinations & Misinformation</li>
          <li>Fairness and Bias in multi-modal generative models: Evaluation and Treatments</li>
          <li>Industry applications of Trustworthy NLP</li>
          <li>Culturally-Aware and Inclusive LLMs</li>
        </ul>
        
        We welcome contributions that also draw upon interdisciplinary knowledge to advance Trustworthy NLP. This may include working with, synthesizing, or incorporating knowledge across expertise, sociopolitical systems, cultures, or norms.        
      </div>
    </div>
  </div>

  <div class="container", style="margin-top: 40px;">
    <div class="row">
      <div class="col-lg-8 mx-auto">
        <h4>Important Dates</h4>
        <ul style="padding-left: 20px;">


          <li><strong>January 30, 2025:</strong> Workshop Paper Due Date (Direct Submission via OpenReview, link TBD)</li>
         <li><strong>February 20, 2025</strong> Workshop Paper Due Date (Fast-Track)</li>
         <li><strong>March 1, 2025:</strong> Notification of Acceptance </li>
         <li><strong>March 10, 2025: </strong> Deadline for relevant NAACL Findings to submit non-archival (Direct submission via form, link TBD) </indent>
          <li><strong>March 10, 2025:</strong> Camera-ready Papers Due</li>
	<li><strong>April 8, 2025:</strong> Pre-recorded video due</li>
          <li><strong>Friday May 3-4, 2025:</strong> TrustNLP Workshop day</li>
      </ul>
      </div>
    </div>
  </div>

  <div class="container", style="margin-top: 20px;">
    <div class="row">
      <div class="col-lg-8 mx-auto">
          <div>
              <h4>Submission Information</h4>
              
              <div>
                <p>
                  All submissions undergo double-blind peer review (with author names and affiliations removed) by the
                  program committee, and they will be assessed based on their relevance to the workshop themes.
              </p>

                  <p>
                      All submissions go through the OpenReview. To submit, use <a href="TBD"> TBD submission link</a>.
                  </p>
                  
                  <p>
                      Submitted manuscripts must be 8 pages long for full papers and 4 pages long for short papers. Please
                      follow <a href="https://2025.naacl.org/calls/papers/#paper-submission-policies">NAACL submission
                          policies</a>. Both full and short papers can have unlimited pages for references and appendices.
                      Please note that at least one of the authors of each accepted paper must register for the workshop and
                      present the paper.
                      Template files can be found <a href="https://aclrollingreview.org/cfp#long-papers">here</a>.
                  </p>
                  <p>
                      We also ask authors to include a limitation section and broader impact statement, following guidelines
                      from the main conference.
                  </p>
              </div> 
          </div>
  
          <div style="margin-top: 10px;">
              <h5>Fast-Track Submission</h5>
              <p>
                  If your paper has been reviewed by ACL, EMNLP, EACL, or ARR and the average rating is higher than 2.5
                  (either average soundness or excitement score), the paper is qualified to be submitted to the fast-track.
                  In the appendix, please include the reviews and a short statement discussing what parts of the paper have
                  been revised.
              </p>
          </div>
  
          <div style="margin-top: 10px;">
              <h5>Non-Archival Option</h5>
              <p>
                  NAACL workshops are traditionally archival. To allow dual submission of work, we are also including a
                  non-archival track. If accepted, these submissions will still participate and present their work in the
                  workshop. A reference to the paper will be hosted on the workshop website (if desired), but will not be
                  included in the official proceedings. Please submit through OpenReview but indicate that this is a cross
                  submission at the bottom of the submission form. You can also skip this step and inform us of your
                  non-archival preference after the reviews. Papers accepted to the Findings of NAACL 2025 may also submit non-archival to the workshop, link TBD.
              </p>
          </div>
          </div>
  
          </div>
        </div>

  <div class="container", style="margin-top: 20px;">
    <div class="row">
      <div class="col-lg-8 mx-auto">
          <div>
              <h4>Policies</h4>

              <p>
                  Accepted and under-review papers are allowed to be submitted to the workshop but will not be included in the
                  proceedings.
              </p>
          </div>
  
              <p>
                  No anonymity period will be required for papers submitted to the workshop, per the latest updates to the
                  ACL anonymity policy. However, submissions must still remain fully anonymized.
              </p>
  
      </div>
  </div>
  </div>
  </section>
  

	






 

  <section id="people" class="bg-light">
    <div class="container">
      
      <div class="row">
      <div class="col-lg-8 mx-auto">
        
      <!-- </div>style="margin-top: -300px;"> -->
        

          <h2>Committee</h2>
          <p class="lead">Organizers</p>
          <ul>
            <li><a href="http://web.cs.ucla.edu/~kwchang/">Kai-Wei Chang</a> - UCLA, Amazon AGI</li>  
            <li><a href="https://anaeliaovalle.github.io/">Anubrata Das</a> - University of Texas at Austin</li> 
	    <li><a href="https://anaeliaovalle.github.io/">Yixin Wan</a> - UCLA</li> 
	    <li><a href="http://scf.usc.edu/~ninarehm/">Ninareh Mehrabi</a> - Amazon AGI</li>
            <li><a href="https://jwaladhamala.com/">Jwala Dhamala</a> - Amazon AGI</li>
            <li><a href="http://ycao95.umiacs.io/">Yang Trista Cao</a> - University of Texas at Austin</li>            
            <li><a href="https://sail.usc.edu/~akramakr/">Anil Ramakrishna</a> - Amazon AGI</li> 
            <li><a href="https://www.isi.edu/people/galstyan/about">Aram Galystan</a> - USC, Amazon AGI</li>
            <li><a href="https://www.amazon.science/author/anoop-kumar">Anoop Kumar</a> - Capital One</li>
            <li><a href="https://guptarah.github.io/">Rahul Gupta</a> - Amazon AGI</li>
          </ul>
        
          
          <p class="lead">Program Committee</p>
          <ul>
<!--             <li>Saied Alshahrani</li>
            <li>Connor Baumler</li>
            <li>Gagan Bhatia</li>
            <li>Keith Burghardt</li>
            <li>Yang Trista Cao</li>
            <li>Javier Carnerero Cano</li>
            <li>Canyu Chen</li>
            <li>Xinyue Chen</li>
            <li>Jwala Dhamala</li>
            <li>Árdís Elíasdóttir</li>
            <li>Aram Galstyan</li>
            <li>Usman Gohar</li>
            <li>Zihao He</li>
            <li>Pengfei He</li>
            <li>Qian Hu</li>
            <li>Satyapriya Krishna</li>
            <li>Jooyoung Lee</li>
            <li>Yanan Long</li>
            <li>Subho Majumdar</li>
            <li>Ninareh Mehrabi</li>
            <li>Sahil Mishra</li>
            <li>Isar Nejadgholi</li>
            <li>Huy Nghiem</li>
            <li>Anaelia Ovalle</li>
            <li>Jieyu Zhao</li>
            <li>Aishwarya Padmakumar</li>
            <li>Kartik Perisetla</li>
            <li>Salman Rahman</li>
            <li>Chahat Raj</li>
            <li>Anthony Rios</li>
            <li>Patricia Thaine</li>
            <li>Simon Yu</li>
            <li>Xinlin Zhuang</li>
            <li>Chupeng Zhang</li>
            <li>Chenyang Zhu</li>
            <li>Christina Chance</li>            
            <li>Nishant Balepur</li>                        
            <li>Elaine Yixin Wan</li>            
            <li>Xinchen Yang</li>                         -->
          </ul>
          
        </div>
      </div>
    </div>

    <div class="container", style="margin-top: 50px;">
      <div class="row">
        <div class="col-lg-8 mx-auto">
                <h5>Interested in reviewing for TrustNLP?</h5>
  
                <p>
                  If you are interested in reviewing submissions, please fill out this <a href="https://forms.gle/AHf3HvWMF3FVDh9q8">form</a>.


                </p>
    
        </div>
    </div>
    </div>

  </section>


  <section id="contact" class="bg-light">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto" style="margin-top: -100px;">
                      <h2>Questions?</h2>
        
                      <p>
                        Please contact us at <a href="mailto:trustnlp24naaclworkshop@googlegroups.com">trustnlp24naaclworkshop@googlegroups.com</a>.
      
      
                      </p>
          </div>
        </div>
      </div>
  </section>



  <section id="Sponsor" class="bg-light">
    <div class="container">
      <div class="col-lg-8 mx-auto">   

        <!-- <div class="row"> -->
          <h2>Thank you to our sponsors!</h2>        
          <div class="sponsor">
            <div class="sponsor-photo">
              <img src="sponsors/amazon-logo-1024x683.png">
      </div>
    </div>
    </section>





  <!-- Footer -->
  <footer class="py-5 bg-dark">
    <div class="container">
      <p class="m-0 text-center text-white">Copyright &copy; TrustNLP 2024</p>
    </div>
    <!-- /.container -->
  </footer>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom JavaScript for this theme -->
  <script src="js/scrolling-nav.js"></script>

</body>

</html>


            <!-- <div>

	<ul>

<li>Griffin Adams, Columbia University </li>
<li>Stefan Arnold, FAU Erlangen-Nurnberg</li>
<li>Connor Baumler, University of Maryland</li>
<li>Keith Burghardt, USC Information Sciences Institute</li>
<li>Yang Trista Cao, University of Maryland</li>
<li>Jwala Dhamala, Amazon Alexa AI-NLU</li>
<li>Jacob Eisenstein, Google</li>
<li>Katja Filippova, Google</li>
<li>Aram Galstyan, USC Information Sciences Institute</li>
<li>Umang Gupta, University of Southern California</li>
<li>Devamanyu Hazarika, Amazon</li>
<li>Zihao He, University of Southern California</li>
<li>William Held, Georgia Tech</li>
<li>Qian Hu, Amazon.com</li>
<li>Fatemah Husain, Kuwait University</li>
<li>Anoop Kumar, Amazon</li>
<li>Sasha Luccioni, Hugging Face</li>
<li>Pranav Narayanan Venkit, Pennsylvania State University</li>
<li>Isar Nejadgholi, National Research Council Canada</li>
<li>Aishwarya Padmakumar, Amazon</li>
<li>Ashwinee Panda, Princeton University</li>
<li>Anirudh Raju, Amazon, Alexa</li>
<li>Anthony Rios, University of Texas at San Antonio</li>
<li>Robik Shrestha, RIT</li>
<li>Anna Sotnikova, University of Maryland</li>
<li>Arjun Subramonian, University of California, Los Angeles</li>
<li>Jialu Wang, University of California, Santa Cruz</li>
<li>Chhavi Yadav, UCSD</li>
<li>Kiyoon Yoo, Seoul National University</li>

	</ul>  	
		</div> -->

  

        <!-- </div>
      </div>
    </div> -->
  <!-- </div> -->


  <!-- <section id="speakers" class="bg-light">
    <div class="container" style="display: none">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <h2>Speakers</h2>
            </br>
            <img src="Diyi_Yang.jpeg" class="icons">
            <strong> <p style="text-align: center; font-size: 20px"> Diyi Yang, Assistant Professor, School of Interactive Computing, Georgia Tech </p></strong>
            <p  style="text-align: center;">Diyi Yang is an assistant professor in the School of Interactive Computing at Georgia Tech. Diyi has broad interests in NLP and Computational Social Science, including dialogue summarization, limited data learning,  hate speech and bias,  as well as responsible NLP for mental health. Her work has received multiple awards (or nominations) at EMNLP, ICWSM, SIGCHI, and CSCW. She is a Microsoft Research Faculty Fellow, a Forbes 30 under 30 in Science, an IEEE “AI 10 to Watch”, a recipient of the Intel Rising Star Faculty Award, the Samsung AI Researcher of the Year and the NSF CAREER Award.</p>

            </br>
            <img src="sbmisi.jpeg" class="icons">
            <strong> <p  style="text-align: center;">Subho Majumdar, Senior Scientist, Splunk</p> </strong>
            <p style="text-align: center;"> Subho is a senior scientist in the Applied ML Research team of Splunk. Before recently joining Splunk, he spent 3 years in AT&T Data Science and AI Research (erstwhile part of AT&T Bell Labs). Throughout his career, he has worked on data-driven solutions that pushed the boundaries for a variety of challenging and cross-product problems. His current focus is on trustworthy machine learning in the wild: not only proposing novel solutions to technical problems that ensure qualities such as fairness, transparency, privacy, and robustness, but also implementing them in real-world use cases.</p>

            </br>
            <img src="Fei_Wang.jpeg" class="icons">
            <strong> <p  style="text-align: center;">Fei Wang, Associate Professor in Division of Health Informatics, Cornell University</p> </strong>
            <p style="text-align: center;">Fei Wang is an Associate Professor in Division of Health Informatics, Department of Population Health Sciences, Weill Cornell Medicine, Cornell University. His major research interest is data mining, machine learning and their applications in health data science. He has published more than 250 papers on the top venues of related areas such as ICML, KDD, NIPS, CVPR, AAAI, IJCAI, JAMA Internal Medicine, Annals of Internal Medicine, Lancet Digital Health, etc. His papers have received over 19,000 citations so far with an H-index 67. His (or his students’) papers have won 8 best paper (or nomination) awards at top international conferences on data mining and medical informatics. His team won the championship of the NIPS/Kaggle Challenge on Classification of Clinically Actionable Genetic Mutations in 2017 and Parkinson's Progression Markers' Initiative data challenge organized by Michael J. Fox Foundation in 2016. Dr. Wang is the recipient of the NSF CAREER Award in 2018, as well as the inaugural research leadership award in IEEE International Conference on Health Informatics (ICHI) 2019. Dr. Wang’s Research has been supported by NSF, NIH, ONR, PCORI, MJFF, AHA, Amazon, etc. Dr. Wang is the past chair of the Knowledge Discovery and Data Mining working group in American Medical Informatics Association (AMIA). Dr. Wang is a fellow of AMIA and a Distinguished Member of ACM.</p>
        </div>
      </div>
    </div>
  </section> -->



